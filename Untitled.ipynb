{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "958dc792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-01 16:50:16,294 loading file /Users/valeriosofi/.flair/models/ner-english-large/models--flair--ner-english-large/snapshots/e2b1caabf7f9bac1e7829db73eac734df7e6ad7b/pytorch_model.bin\n",
      "2022-09-01 16:50:37,053 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.embeddings import TransformerWordEmbeddings, TransformerDocumentEmbeddings\n",
    "\n",
    "model = SequenceTagger.load(\"ner-large\")\n",
    "model.eval()\n",
    "assert isinstance(model.embeddings, (TransformerWordEmbeddings, TransformerDocumentEmbeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "589cb762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "sentences = [Sentence(\"Hi Pier, nice to meet you\"), Sentence(\"This is the first positive result!\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e97ea87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"George Washington went to Washington .\" → [\"George Washington\"/PER, \"Washington\"/LOC]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = Sentence('George Washington went to Washington.')\n",
    "model.predict(sentence)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf6eee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeriosofi/Projects/valerio/flair/flair/embeddings/transformer.py:1158: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  word_ids.shape[0], int(lengths.max()), self.embedding_length_internal, device=flair.device\n",
      "01/09/2022 04:51:19 PM Running pipeline: pytorch_pipeline\n",
      "01/09/2022 04:51:19 PM Running step: no_compression\n",
      "01/09/2022 04:51:19 PM Running step: optimizer_step\n",
      "01/09/2022 04:51:19 PM Optimizations: ('torchscript',)\n",
      "  0%|                                                                                                                                                                                                                                                                                             | 0/1 [00:00<?, ?it/s]01/09/2022 04:51:19 PM Optimizing output of no_compression\n",
      "\n",
      "  0%|                                                                                                                                                                                                                                                                                             | 0/1 [00:00<?, ?it/s]\u001b[A01/09/2022 04:51:19 PM Optimizing with PytorchBackendOptimizer and q_type: None.\n",
      "01/09/2022 04:51:20 PM Compilation failed with torch interface of ModelCompiler.TORCHSCRIPT. Got error keyword-arg expansion is not supported:\n",
      "  File \"/Users/valeriosofi/Projects/valerio/flair/flair/embeddings/transformer.py\", line 1110\n",
      "        if attention_mask is not None:\n",
      "            model_kwargs[\"attention_mask\"] = attention_mask\n",
      "        hidden_states = self.model(input_ids, **model_kwargs)[-1]\n",
      "                                                ~~~~~~~~~~~~ <--- HERE\n",
      "    \n",
      "        # make the tuple a tensor; makes working with it easier.\n",
      ". If possible the compilation will be re-scheduled with another interface. Please consult the documentation for further info or open an issue on GitHub for receiving assistance.\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.45it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.34it/s]\n",
      "01/09/2022 04:51:20 PM Running pipeline: onnx_pipeline\n",
      "01/09/2022 04:51:20 PM Running step: no_compression\n",
      "01/09/2022 04:51:20 PM Running step: optimizer_step\n",
      "01/09/2022 04:51:20 PM Optimizations: ('onnxruntime',)\n",
      "  0%|                                                                                                                                                                                                                                                                                             | 0/1 [00:00<?, ?it/s]01/09/2022 04:51:20 PM Optimizing output of no_compression\n",
      "\n",
      "  0%|                                                                                                                                                                                                                                                                                             | 0/1 [00:00<?, ?it/s]\u001b[A01/09/2022 04:51:20 PM Optimizing with ONNXOptimizer and q_type: None.\n",
      "2022-09-01 15:51:22.984151 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3724'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986311 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3723'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986316 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3722'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986320 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3728'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986356 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3776'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986477 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3774'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986484 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3780'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986487 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3775'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986508 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3922'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986510 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3920'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986514 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3921'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986517 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3926'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986532 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3974'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986535 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3978'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986537 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3973'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986540 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '3972'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986552 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4195'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986555 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4197'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986557 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4179'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986560 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4188'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986562 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4159'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986565 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4155'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986567 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4154'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986570 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4087'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986573 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4153'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986593 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4132'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986596 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4135'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986598 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4117'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986601 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4121'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986603 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4137'. It is not used by any node and should be removed from the model.\n",
      "2022-09-01 15:51:22.986606 [W:onnxruntime:, graph.cc:3526 CleanUnusedInitializersAndNodeArgs] Removing initializer '4116'. It is not used by any node and should be removed from the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.23s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.23s/it]\n"
     ]
    }
   ],
   "source": [
    "model.embeddings = model.embeddings.optimize_nebuly(sentences, ignore_compilers=[\"tvm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4248dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "febd60d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"George Washington went to Washington .\" → [\"George Washington went to Washington .\"/MISC]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = Sentence('George Washington went to Washington.')\n",
    "model.predict(sentence)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39855242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
